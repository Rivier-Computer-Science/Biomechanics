{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cricket Biomechanics Analysis Demo\n",
    "\n",
    "This notebook demonstrates the key components of the cricket straight drive biomechanics analysis system. It shows how to:\n",
    "\n",
    "1. Extract pose data from a cricket batting video\n",
    "2. Calculate joint angles and other biomechanical features\n",
    "3. Visualize the results\n",
    "4. Prepare data for the LSTM model\n",
    "\n",
    "**Note:** For Sprint 1, this is a demonstration notebook showing the planned workflow. In future sprints, we will incorporate actual data and complete the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append('../')\n",
    "\n",
    "# Import our modules\n",
    "from src.data_collection.pose_extractor import PoseExtractor\n",
    "from src.feature_engineering.joint_angles import JointAngleCalculator\n",
    "from src.visualization.pose_visualizer import PoseVisualizer\n",
    "from src.model.lstm_model import StraightDriveClassifier, StraightDriveLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "First, let's set up the paths and load the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "config_path = \"../configs/config.yaml\"\n",
    "data_dir = \"../data\"\n",
    "raw_dir = os.path.join(data_dir, \"raw\")\n",
    "processed_dir = os.path.join(data_dir, \"processed\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Load configuration\n",
    "import yaml\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded successfully.\")\n",
    "print(f\"Using {config['pose']['model']} for pose estimation.\")\n",
    "print(f\"Model type: {config['model']['type']}\")\n",
    "print(f\"Sequence length: {config['model']['sequence_length']} frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection\n",
    "\n",
    "This section demonstrates how to extract pose data from a cricket batting video. In a real implementation, you would provide your own video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pose extractor\n",
    "pose_extractor = PoseExtractor(config_path)\n",
    "\n",
    "# Example (commented out as we don't have a real video file yet)\n",
    "# video_path = os.path.join(raw_dir, \"sample_straight_drive.mp4\")\n",
    "# pose_data = pose_extractor.process_video(video_path, output_dir=processed_dir, visualize=True)\n",
    "\n",
    "# For demonstration, we'll create a sample pose data structure\n",
    "def create_sample_pose_data():\n",
    "    \"\"\"Create sample pose data for demonstration\"\"\"\n",
    "    # Sample landmarks for 10 frames\n",
    "    frames = []\n",
    "    for i in range(10):\n",
    "        # Create 33 landmarks (MediaPipe standard)\n",
    "        landmarks = []\n",
    "        for j in range(33):\n",
    "            # Add some simulated movement\n",
    "            landmarks.append({\n",
    "                'x': 0.5 + 0.1 * np.sin(i * 0.1 + j * 0.05),\n",
    "                'y': 0.5 + 0.1 * np.cos(i * 0.1 + j * 0.05),\n",
    "                'z': 0.1 * np.sin(i * 0.1),\n",
    "                'visibility': 0.9\n",
    "            })\n",
    "        \n",
    "        frames.append({\n",
    "            'frame_idx': i,\n",
    "            'timestamp': i / 30.0,  # Assuming 30 FPS\n",
    "            'landmarks': landmarks\n",
    "        })\n",
    "    \n",
    "    pose_data = {\n",
    "        'video_name': 'sample_straight_drive.mp4',\n",
    "        'fps': 30.0,\n",
    "        'frame_count': 10,\n",
    "        'frames': frames\n",
    "    }\n",
    "    \n",
    "    return pose_data\n",
    "\n",
    "# Create sample data\n",
    "sample_pose_data = create_sample_pose_data()\n",
    "\n",
    "# Save sample data\n",
    "sample_pose_path = os.path.join(processed_dir, \"sample_pose.json\")\n",
    "with open(sample_pose_path, 'w') as f:\n",
    "    json.dump(sample_pose_data, f, indent=2)\n",
    "\n",
    "print(f\"Generated sample pose data with {len(sample_pose_data['frames'])} frames.\")\n",
    "print(f\"Each frame has {len(sample_pose_data['frames'][0]['landmarks'])} landmarks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Now, let's calculate joint angles and other biomechanical features from the pose data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the joint angle calculator\n",
    "angle_calculator = JointAngleCalculator()\n",
    "\n",
    "# Process the sample pose data\n",
    "df = angle_calculator.process_pose_data(sample_pose_path)\n",
    "# Calculate dynamic features (velocities, accelerations)\n",
    "df_with_dynamics = angle_calculator.calculate_dynamic_features(df)\n",
    "\n",
    "# Save the features\n",
    "features_path = os.path.join(processed_dir, \"sample_features.csv\")\n",
    "df_with_dynamics.to_csv(features_path, index=False)\n",
    "\n",
    "# Show the first few rows\n",
    "print(\"Generated biomechanical features:\")\n",
    "df_with_dynamics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization\n",
    "\n",
    "Let's visualize the joint angles we calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pose visualizer\n",
    "visualizer = PoseVisualizer(config_path)\n",
    "\n",
    "# Get angle columns (for demonstration)\n",
    "angle_columns = [col for col in df_with_dynamics.columns if 'angle' in col]\n",
    "\n",
    "# Create a time series plot\n",
    "fig = visualizer.create_angle_time_series_plot(\n",
    "    df_with_dynamics,\n",
    "    angle_columns,\n",
    "    os.path.join(processed_dir, \"angle_plot.png\")\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "for col in angle_columns:\n",
    "    plt.plot(df_with_dynamics['timestamp'], df_with_dynamics[col], label=col)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Angle (degrees)')\n",
    "plt.title('Joint Angles During Cricket Straight Drive')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparing Data for the LSTM Model\n",
    "\n",
    "Now, let's prepare the data for the LSTM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier\n",
    "classifier = StraightDriveClassifier(config_path)\n",
    "\n",
    "# For demonstration, let's add a dummy label column\n",
    "df_with_dynamics['technique_label'] = 1  # 1 = correct, 0 = incorrect\n",
    "\n",
    "# Prepare sequences for the LSTM model\n",
    "seq_length = config['model']['sequence_length']\n",
    "sequences, labels = classifier.prepare_sequences(\n",
    "    df_with_dynamics,\n",
    "    label_col='technique_label',\n",
    "    seq_length=min(seq_length, len(df_with_dynamics) - 1)  # Ensure we have enough data\n",
    ")\n",
    "\n",
    "print(f\"Prepared {len(sequences)} sequences with shape {sequences.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architecture\n",
    "\n",
    "Here, we'll demonstrate the LSTM model architecture. In future sprints, we'll implement the actual training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "input_size = sequences.shape[2]  # Number of features\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "model = classifier.build_model(input_size, num_classes)\n",
    "\n",
    "# Print model summary\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"LSTM Model Architecture:\")\n",
    "print(f\"- Input size: {input_size}\")\n",
    "print(f\"- Hidden size: {config['model']['hidden_units']}\")\n",
    "print(f\"- Output classes: {num_classes}\")\n",
    "print(f\"- Total trainable parameters: {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "In future sprints, we will:\n",
    "\n",
    "1. Collect and label real cricket batting videos\n",
    "2. Extract pose data using MediaPipe\n",
    "3. Engineer comprehensive biomechanical features\n",
    "4. Train and evaluate the LSTM model\n",
    "5. Implement real-time feedback mechanisms\n",
    "6. Create a user interface for coaches and players\n",
    "\n",
    "The foundation laid in Sprint 1 provides the structure for all these future developments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
